{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Aut1367 brain\n",
    "In order to process the Aut1367 brain, I began by downloading the corresponding level 0 image from ndio.\n",
    "The script I used is attached below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Following https://github.com/neurodata/ndio-demos/blob/master/Getting%20Started.ipynb\n",
    "import ndio\n",
    "ndio.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ndio.remote.neurodata as neurodata\n",
    "nd = neurodata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKEN = \"Aut1367\"\n",
    "CHANNEL = \"Aut1367_stitched\"\n",
    "\n",
    "TOKEN in public_tokens # Should *definitely* be true\n",
    "\n",
    "## I see it in ndviz, so hopefully this is ok..  (it did work, although it's not in public_tokens, which makes sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## RUN 2: (RUN 1 had dimensions that were much too narrow)\n",
    "\n",
    "query = {\n",
    "    'token': TOKEN,\n",
    "    'channel': CHANNEL,\n",
    "    'x_start': 10000,\n",
    "    'x_stop': 15000,\n",
    "    'y_start': 10000,\n",
    "    'y_stop': 15000,\n",
    "    'z_start': 500,\n",
    "    'z_stop': 505,\n",
    "    'resolution': 0\n",
    "}\n",
    "\n",
    "aut_1367 = nd.get_cutout(**query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print type(aut_1367)\n",
    "\n",
    "from PIL import Image\n",
    "print aut_1367.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "## if we have (i, j, k), we want (k, j, i)  (converts nibabel format to sitk format)\n",
    "new_im = aut_1367.swapaxes(0,2) # just swap i and k\n",
    "\n",
    "plane = 0;\n",
    "for plane in (0, 1, 2, 3, 4, 5):\n",
    "    output = np.asarray(new_im[plane])\n",
    "    ## Save as TIFF for Ilastik\n",
    "    scipy.misc.toimage(output).save('RAWoutfile' + 'aut1367_' + str(plane) + '.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we've now saved 5 TIFF slices of the aut_1367 brain from between z = 500 and z = 505.  An example of a TIFF slice at this resolution shows:\n",
    "\n",
    "\n",
    "**Aut1367 at z = 500, level 0 (from ndio):**\n",
    "![aut1367_level0_z500](autlevel0/RAWoutfileaut1367_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now see from the above image some sort of structure to the right (grey matter, white matter).  However, if I'm trying to detect individual membranes, do I just highlight the boundary between the grey and white matter?  I'm meeting with Greg on Friday at 10 AM to go over this in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
